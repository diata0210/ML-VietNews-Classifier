Câu hỏi cứu giám đốc Ferrari khỏi lừa đảo deepfake
"Này, anh có nghe về thương vụ cực lớn mà tập đoàn chúng ta đang lên kế hoạch không? Tôi cần sự giúp đỡ của anh", một tin nhắn WhatsApp gửi đến vị giám đốc từ một người tự nhận là CEO Ferrari Benedetto Vigna.Nói với Bloomberg, người này cho biết tin nhắn không đến từ số liên lạc thông thường của Vigna. Ảnh đại diện cũng khác, dù đó là hình CEO đeo kính tạo dáng trong bộ vest và cà vạt, tay khoanh trước logo hình ngựa Ferrari quen thuộc."Hãy chuẩn bị ký thỏa thuận bảo mật mà luật sư sẽ lập tức gửi cho anh", một tin nhắn khác được gửi đến. "Cơ quan quản lý thị trường của Italy và sàn giao dịch chứng khoán Milan đã nhận thông báo. Anh hãy chuẩn bị sẵn sàng nhưng cũng cần thận trọng".
Giám đốc Ferrari sau đó tiếp tục nhận một cuộc gọi bằng video với hình ảnh và giọng nói từ số này. "Hình ảnh và giọng điệu rất giống Vigna. Việc bắt chước giọng miền nam Italy của ông ấy rất chính xác, rất thuyết phục", người này nói.Trong cuộc gọi, kẻ đóng giả Vigna giải thích việc phải gọi bằng số liên lạc khác là vì "cần thảo luận một vấn đề bí mật và lo ngại có thể bị Trung Quốc thu thập". Tuy nhiên, vị giám đốc bắt đầu nghi ngờ, nhận ra "ngữ điệu máy móc" trong câu nói, dù chi tiết này theo ông rất khó phát hiện."Xin lỗi, Benedetto, nhưng tôi cần xác định danh tính của anh", người này hỏi lại. "Tiêu đề cuốn sách anh vừa giới thiệu cho tôi vài ngày trước là gì?".Cuộc gọi đột ngột kết thúc. Số điện thoại không thể liên lạc được sau đó.Vị giám đốc cho biết Ferrari đã mở một cuộc điều tra nội bộ. Hãng xe không bình luận về câu chuyện.Đây không phải lần đầu một CEO bị mạo danh bằng deepfake. Theo WSJ, vào tháng 5, Mark Read, CEO tập đoàn truyền thông WPP, cũng bị giả mạo để thực hiện cuộc gọi deepfake qua Microsoft Teams. Vụ lừa đảo được đánh giá tinh vi, nhưng không thành công.Đầu năm nay, một công ty đa quốc gia giấu tên mất 26 triệu USD sau khi những kẻ gian nhắm vào nhân viên ở văn phòng tại Hong Kong. Theo SCMP, kẻ xấu sử dụng deepfake giả mạo giám đốc tài chính của công ty, dụ nhân viên chuyển tiền. Cuối tháng 5, Ủy ban Cạnh tranh và Người tiêu dùng Australia (ACCC) cho biết người dân nước này mất 8 triệu USD riêng trong năm nay vì những kẻ lừa đảo sử dụng các nền tảng đầu tư online và lợi dụng tính năng của deepfake."Năm nay, chúng ta chứng kiến sự gia tăng số lượng tội phạm cố gắng sao chép giọng nói và hình ảnh bằng AI", Rachel Tobac, CEO của công ty đào tạo an ninh mạng SocialProof Security (Mỹ), viết trên blog đầu tháng 7.Cũng theo Tobac, người dùng không nên tin tưởng các cuộc gọi liên quan đến chuyển tiền, cung cấp thông tin tài chính hoặc tài khoản đăng nhập. Để xác định chính xác ai đang liên lạc với mình, người dùng cần đặt câu hỏi mà chỉ hai người biết với nhau - bước xác thực cơ bản nhưng cần thiết.Deepfake là sự kết hợp giữa "deep learning" (học sâu) và "fake" (giả mạo) để ghép khuôn mặt, giọng nói... của bất kỳ ai vào bất kỳ nội dung gì, tạo cảm giác như thật. Công nghệ này gây lo ngại thời gian qua khi bị lợi dụng cho mục đích giả mạo, lừa đảo. Sự đột phá của AI qua càng khiến các bức ảnh deepfake khó nhận biết, trong khi người dùng dễ tiếp cận mà không cần am hiểu sâu."Chỉ là vấn đề thời gian. Công cụ deepfake tinh vi dựa trên AI sẽ trở nên cực kỳ chính xác, đến mức không thể phân biệt thời gian tới", Stefano Zanero, chuyên gia an ninh mạng của Politecnico di Milano (Italy), nói.
Phát hiện deepfake bằng thiên văn học
Vấn nạn deepfake mạo danh bác sĩ trên mạng xã hội
Người chồng bị nghi dùng ảnh deepfake để tố vợ ngoại tình
Cách kẻ gian dùng deepfake để lừa hàng triệu USD
Ba câu chuyện cho thấy sự nguy hiểm của deepfake
Phát hiện deepfake bằng thiên văn học
Vấn nạn deepfake mạo danh bác sĩ trên mạng xã hội
Người chồng bị nghi dùng ảnh deepfake để tố vợ ngoại tình
Cách kẻ gian dùng deepfake để lừa hàng triệu USD
Ba câu chuyện cho thấy sự nguy hiểm của deepfake
