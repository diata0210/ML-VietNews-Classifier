Telegram thành ổ deepfake khiêu dâm, nhiều phụ nữ kêu cứu
Những ngày qua, hàng loạt phụ nữ Hàn Quốc đã lên mạng xã hội X nói về việc bị bạo hành thông qua việc dùng công nghệ deepfake và AI để gán ghép khuôn mặt. Những video nhạy cảm này sau đó được gửi lên các hội nhóm Telegram với hàng nghìn người, chủ yếu là đàn ông. Nền tảng này không có cơ chế kiểm duyệt khiến chúng càng lan xa mà không ai ngăn cản được.
Từ lời kêu cứu của một nữ sinh viên"Chúng tôi không phải gái điếm, chúng tôi không tồn tại để thỏa mãn nhu cầu tình dục của ai đó. Chúng tôi là những con người có phẩm giá, mỗi người đều có sự nghiệp và ước mơ riêng" là một phần của bức thư mà nữ sinh viên có biệt danh Ruma dự định gửi lên tòa án Hàn Quốc và được đăng trên Hankyoreh tuần này.Cô là một trong số nhiều sinh viên nữ vừa tốt nghiệp Đại học Quốc gia Seoul có khuôn mặt xuất hiện trong các video deepfake khiêu dâm tạo bằng AI, sau đó bị những nam sinh là bạn học cùng trường phát tán thông qua Telegram.Vào tháng 7/2021, Ruma nhận được ảnh nhạy cảm có khuôn mặt của cô trên Telegram. Nhưng phải ba năm sau, vào tháng 5, cô mới biết kẻ đứng sau là hai bạn học nam, cũng vừa tốt nghiệp. Hai người đã bị bắt và sắp bị đưa ra xét xử.Khi phát hiện, Ruma đã báo cáo sự việc tới bốn đồn cảnh sát khác nhau. Nhưng trong gần hai năm sau đó, cảnh sát không thể bắt được thủ phạm. Cô không bỏ cuộc, cố gắng cùng các nạn nhân khác thu thập chứng cứ."Sẽ là cơn ác mộng khi phải đối mặt với mọi người mỗi khi thức dậy buổi sáng. Lần đầu tiên kể từ khi sinh ra, tôi nghĩ mình không muốn sống trên thế giới này nữa. Nhưng có một lý do khiến tôi kiên trì: Không ai phải chịu đau khổ như tôi. Không ai phải bị coi là vật thể chỉ vì là phụ nữ. Và không ai phải bị đối xử như một công cụ để xoa dịu mặc cảm tự ti của kẻ bệnh hoạn", Ruma viết trong thư. "Tôi hy vọng không ai khác phải đối mặt nỗi đau này".
Thực tế, đã có một số báo cáo về việc các deepfake khiêu dâm lan truyền trong một số cộng đồng trường đại học thông qua ứng dụng nhắn tin, phổ biến nhất là Telegram. Hình thức điển hình là: kẻ xấu lấy hình ảnh của bạn bè hoặc người quen, sử dụng công cụ AI để tạo deepfake, đăng lên Telegram với mục đích mua vui, thậm chí gửi cho nạn nhân như một hình thức bắt nạt.Theo Hankyoreh, trong một nhóm Telegram với hơn 1.300 thành viên được phân loại theo 70 trường đại học Hàn Quốc, các thành viên sẽ đăng ảnh những cô gái họ biết kèm thông tin cá nhân, chuyên ngành học. Những người khác nếu quen người trong ảnh sẽ cùng phản hồi. Cuối cùng, chúng tập hợp cùng nhau qua phòng chat riêng và tạo nội dung khiêu dâm.Ngay cả khi phát hiện, nạn nhân không thể làm gì, bởi họ không biết ai đã tạo deepfake, cũng như mặc cảm và xấu hổ không thể chia sẻ với ai. Trước bức thư của Ruma, truyền thông Hàn Quốc hiếm khi phản ánh nạn khiêu dâm deepfake. Một số nạn nhân phải tự giải quyết vấn đề thông qua mạng xã hội. Dù vậy, khi thư của Ruma được đăng, họ mới được chú ý hơn. Đặc biệt, các hashtag như #2ndMeToo_SK giúp nhiều người biết tới. Truyền thông lúc này cũng vào cuộc.Hành động của chính phủHàn Quốc từng đấu tranh để xóa bỏ cái gọi là molka - video quay lén có nội dung khiêu dâm, còn hiện phải vật lộn với làn sóng deepfake. Dù vậy, trong thời gian dài, chính quyền nước này không đưa ra hành động quyết liệt, cho đến khi thư của Ruma xuất hiện."Video deepfake nhắm vào các cá nhân không xác định đã lan truyền nhanh chóng trên mạng xã hội", Tổng thống Hàn Quốc Yoon Suk Yeol phát biểu trong một cuộc họp nội các ngày 28/8. "Nhiều nạn nhân là trẻ vị thành niên. Hầu hết thủ phạm cũng được xác định là thanh thiếu niên".Ông Yeol kêu gọi các nhà chức trách điều tra và giải quyết triệt để tội phạm tình dục kỹ thuật số. "Đây là hành vi khai thác công nghệ trong khi vẫn dựa vào sự bảo vệ ẩn danh. Nó rõ ràng là hành vi phạm tội", ông nhấn mạnh.Cùng ngày, Yonhap dẫn nguồn tin chính phủ cho biết cảnh sát sẽ tích cực truy lùng những người tạo và phát tán deepfake khiêu dâm. Chiến dịch sẽ kéo dài bảy tháng, bắt đầu vào 28/8, tập trung vào những kẻ bóc lột trẻ em và thanh thiếu niên.Theo Cơ quan Cảnh sát Hàn Quốc, 297 vụ phạm tội deepfake tình dục đã được báo cáo trong bảy tháng đầu năm, tăng từ 180 vụ vào năm ngoái và gần gấp đôi năm 2021 - năm đầu tiên dữ liệu được thu thập. Trong số 178 người bị buộc tội, 113 là thanh thiếu niên.Tuy nhiên, vấn đề nghiêm trọng hơn so với số liệu chính thức. Theo Guardian, trong một phòng chat Telegram có 220.000 thành viên, rất nhiều hình ảnh deepfake được chia sẻ, chủ yếu là phụ nữ và trẻ em gái. Truyền thông Hàn Quốc cho biết nạn nhân gồm sinh viên đại học, giáo viên và quân nhân.Liên đoàn Giáo viên và Nhân viên Giáo dục Hàn Quốc nói đã ghi nhận về video deepfake khiêu dâm liên quan đến học sinh. Đơn vị này cũng gửi yêu cầu Bộ Giáo dục Hàn Quốc điều tra.Theo Reuters, vấn nạn deepfake lan truyền trên Telegram tiếp tục khiến nền tảng bị hoen ố về mặt hình ảnh. Trước đó, vào năm 2020, cảnh sát Hàn Quốc phát hiện một đường dây tống tiền tình dục trực tuyến hoạt động chủ yếu trong các phòng chat của ứng dụng này. Khi đó, thủ lĩnh đường dây Cho Ju-bin bị kết án 40 năm tù vì tống tiền ít nhất 74 phụ nữ, trong đó có 16 thiếu niên.Theo Đạo luật Bảo vệ nạn nhân và Phòng ngừa bạo lực tình dục của Hàn Quốc, hành vi tạo video deepfake có nội dung khiêu dâm với mục đích phát tán có thể bị phạt tù 5 năm hoặc phạt tiền 50 triệu won (37.500 USD).Deepfake là sự kết hợp giữa "deep learning" (học sâu) và "fake" (giả). Công nghệ này sử dụng AI phân tích cử chỉ, nét mặt và giọng nói của một người, từ đó tái tạo và chỉnh sửa để cho ra đời ảnh hoặc video trông như thật về người đó, thậm chí tạo được cả giọng nói.
Ảnh không còn là 'bảo chứng sự thật' trong kỷ nguyên AI
Lo ngại về trách nhiệm kiểm duyệt mạng xã hội sau vụ bắt CEO Telegram
Telegram bị ví như hang ổ online của tội phạm mạng
Bất lực với công cụ AI tạo ảnh khỏa thân
Cách kẻ gian dùng deepfake để lừa hàng triệu USD
Ảnh không còn là 'bảo chứng sự thật' trong kỷ nguyên AI
Lo ngại về trách nhiệm kiểm duyệt mạng xã hội sau vụ bắt CEO Telegram
Telegram bị ví như hang ổ online của tội phạm mạng
Bất lực với công cụ AI tạo ảnh khỏa thân
Cách kẻ gian dùng deepfake để lừa hàng triệu USD
