{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiền xử lý văn bản tiếng Việt\n",
    "\n",
    "Trong notebook này, chúng ta sẽ thực hiện tiền xử lý văn bản tiếng Việt. Các bước tiền xử lý bao gồm:\n",
    "\n",
    "1. Chuẩn hóa văn bản tiếng Việt.\n",
    "2. Loại bỏ các từ không có nghĩa (stopwords).\n",
    "3. Làm sạch các dấu câu thừa, URL, email, số và khoảng trắng dư thừa.\n",
    "4. Xử lý và lưu dữ liệu vào các tệp CSV.\n",
    "5. Sử dụng xử lý song song để tăng tốc độ khi làm việc với nhiều tệp dữ liệu.\n",
    "\n",
    "### Cài đặt môi trường\n",
    "\n",
    "python 3.8.10\n",
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ô 1: Import các thư viện cần thiết\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "from underthesea import word_tokenize, text_normalize\n",
    "import unicodedata\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Thiết lập logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Tải stopwords tiếng Việt nếu chưa tải\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "stop_words = set([\n",
    "    # Các stopwords đã định nghĩa trước đó\n",
    "    \"tôi\", \"tao\", \"mày\", \"chúng_tôi\", \"chúng_ta\", \"mình\", \"họ\", \"hắn\", \"nó\", \"chúng\", \"bạn\",\n",
    "    \"là\", \"được\", \"có\", \"bị\", \"đang\", \"đã\", \"sẽ\", \"chưa\", \"đều\", \"phải\", \"cần\", \"muốn\",\n",
    "    \"và\", \"hay\", \"hoặc\", \"nhưng\", \"vì\", \"nên\", \"bởi_vì\", \"do_đó\", \"vậy_nên\",\n",
    "    \"của\", \"cho\", \"trong\", \"ngoài\", \"trên\", \"dưới\", \"với\", \"về\", \"từ\", \"đến\",\n",
    "    \"rất\", \"khá\", \"thật\", \"còn\", \"đã\", \"vẫn\", \"mới\", \"liền\", \"luôn\", \"lại\", \"cứ\",\n",
    "    \"này\", \"kia\", \"ấy\", \"đó\", \"những\", \"mọi\", \"các\", \"mỗi\", \"từng\",\n",
    "    \"không\", \"chẳng\", \"đừng\", \"chả\", \"năng\", \"chưa\", \"chỉ\", \"mới\",\n",
    "    \"một\", \"hai\", \"ba\", \"mấy\", \"vài\", \"nhiều\", \"ít\",\n",
    "    \"hôm_nay\", \"ngày_mai\", \"hôm_qua\", \"bây_giờ\", \"lúc\", \"khi\", \"vừa\",\n",
    "    \"cả\", \"tất_cả\", \"một_số\", \"một_vài\", \"một_chút\",\n",
    "    \"thì\", \"mà\", \"để\", \"như\", \"là\", \"theo\", \"qua\", \"gì\", \"bởi\", \"vậy\",\n",
    "    \"rằng\", \"rồi\", \"thế\", \"thế_là\", \"vẫn\", \"việc\", \"suốt\", \"quá\",\n",
    "    \"cho_nên\", \"vì_thế\", \"do_vậy\", \"như_là\", \"có_thể\", \"phải_chi\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuẩn hóa văn bản tiếng Việt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vietnamese_text(text):\n",
    "    \"\"\"\n",
    "    Chuẩn hoá văn bản tiếng Việt\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    text = text_normalize(text)\n",
    "    text = re.sub(r'[„\"\\'`’]', ' ', text)\n",
    "    text = re.sub(r'\\.+', \".\", text)\n",
    "    text = re.sub(r'\\?+', \"?\", text)\n",
    "    text = re.sub(r'\\!+', \"!\", text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hàm loại bỏ stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Loại bỏ từ không có nghĩa (stopwords)\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words and word.strip()]\n",
    "    return \" \".join(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiền xử lý văn bản tiếng Việt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_vietnamese_text(text):\n",
    "    \"\"\"\n",
    "    Tiền xử lý văn bản tiếng Việt: chuẩn hóa, loại bỏ stopwords, các dấu câu thừa và dữ liệu không cần thiết.\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        # Chuyển thành chữ thường\n",
    "        text = text.lower()\n",
    "\n",
    "        # Chuẩn hoá văn bản\n",
    "        text = normalize_vietnamese_text(text)\n",
    "        \n",
    "        # Loại bỏ từ không có nghĩa\n",
    "        text = remove_stopwords(text)\n",
    "        \n",
    "        # Loại bỏ cụm \"dân trí\" bất kể hoa hay thường\n",
    "        text = re.sub(r'dân\\s*trí', '', text, flags=re.IGNORECASE)\n",
    "        \n",
    "        # Gộp các thao tác regex: loại bỏ URL, email, số, dấu câu thừa và khoảng trắng dư thừa\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+|\\S+@\\S+|\\d+|[^\\w\\s]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()  # Loại bỏ khoảng trắng thừa\n",
    "        \n",
    "        return text\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kiểm tra và tạo thư mục nếu chưa tồn tại\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_directory_exists(path):\n",
    "    \"\"\"\n",
    "    Kiểm tra và tạo thư mục nếu không tồn tại\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiền xử lý tệp văn bản đơn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_single_file(input_path):\n",
    "    \"\"\"\n",
    "    Tiền xử lý tệp văn bản đơn và trả về văn bản đã làm sạch.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(input_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            text = file.read()\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File {input_path} không tìm thấy.\")\n",
    "        return None\n",
    "    except UnicodeDecodeError:\n",
    "        logging.error(f\"Lỗi giải mã file {input_path}.\")\n",
    "        return None\n",
    "\n",
    "    # Làm sạch văn bản\n",
    "    cleaned_text = clean_vietnamese_text(text)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiền xử lý nhiều tệp và lưu kết quả vào CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_multiple_files(categories):\n",
    "    \"\"\"\n",
    "    Tiền xử lý nhiều tệp theo thể loại và lưu kết quả vào các tệp CSV.\n",
    "    \"\"\"\n",
    "    for category in categories:\n",
    "        input_folder = f\"data/raw/{category}/\"\n",
    "        output_path = f\"data/processed/{category}.csv\"\n",
    "        \n",
    "        # Kiểm tra xem thư mục có tồn tại không\n",
    "        if not os.path.exists(input_folder):\n",
    "            logging.error(f\"Thư mục {input_folder} không tồn tại.\")\n",
    "            continue\n",
    "        \n",
    "        all_cleaned_texts = []\n",
    "        filenames = [filename for filename in os.listdir(input_folder) if filename.endswith('.txt')]\n",
    "\n",
    "        # Duyệt qua tất cả các file .txt trong thư mục thể loại\n",
    "        for i, filename in enumerate(filenames):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            cleaned_text = preprocess_single_file(input_path, output_path, is_last_file=(i == len(filenames)-1))\n",
    "            if cleaned_text:\n",
    "                all_cleaned_texts.append(cleaned_text)\n",
    "\n",
    "        # Nếu có dữ liệu sau khi tiền xử lý, lưu vào CSV\n",
    "        if all_cleaned_texts:\n",
    "            ensure_directory_exists(os.path.dirname(output_path))\n",
    "            df = pd.DataFrame({\"cleaned_text\": all_cleaned_texts})\n",
    "            df.to_csv(output_path, index=False)\n",
    "            logging.info(f\"Đã lưu tệp đã xử lý vào {output_path}\")\n",
    "        else:\n",
    "            logging.warning(f\"Không có dữ liệu nào để lưu cho thể loại {category}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    categories = ['sports', 'politics', 'technology', 'health', 'lifestyle', 'law']\n",
    "    \n",
    "    # Tiền xử lý tệp với nhiều thể loại song song\n",
    "    preprocess_multiple_files(categories)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kết luận\n",
    "\n",
    "- Chúng ta đã xây dựng một quy trình tiền xử lý văn bản cho tiếng Việt với các bước như chuẩn hóa văn bản, loại bỏ stopwords và xử lý các tệp văn bản lớn bằng cách sử dụng xử lý song song.\n",
    "- Bạn có thể chạy chương trình này trong môi trường của mình để tiền xử lý các tệp văn bản tiếng Việt.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
